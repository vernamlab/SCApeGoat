{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Side Channel Analysis Metric API\n",
    "There exists very few comprehensive open-source libraries for side-channel analysis. Libraries that do exist are difficult to use and lack the proper documentation. This Jupyter Notebook outlines some of the most useful metrics when conducting side channel analysis in an easy to understand medium. These metrics do not perform an attack, rather they are used to assess gain insight into the cryptographic system. Many of the metrics in this API require data to be pre-formatted prior to use. However, each metric explains what programmer needs to provide. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f9edd07ef33dc4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18d57964c6d725bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Signal-to-Noise Ratio \n",
    "The signal-to-noise ratio of a signal is defined as the ratio of a signal's data component to the signal's noise component. For side-channel analysis, the SNR of a power trace relates to the ability for an attacker to obtain information from a power trace during an attack. The effectiveness of side channel attack increases for larger SNR values since the signal leakage is more prominent relative to the noise of the signal. Typically recorded power traces need to be partitioned into different sets called labels. \n",
    "\n",
    "$$\n",
    "SNR = \\frac{VAR(L_d)}{VAR(L_n)} = \\frac{\\sum_{v=0}^{V} (\\hat{\\mu_v}^2 - \\hat{\\mu})^2}{\\hat{\\sigma}^2}\n",
    "$$\n",
    "The resulting array is the value of the SNR at a given discrete time sample. Windows of the resulting trace where the magnitude of the SNR is high may also indicate an area of interest since it implies that there exists a significant amount of leakage at that sample."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec9b8e1b8e3bf69b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def signal_to_noise_ratio(labels):\n",
    "    # statistical mean and variances of each set\n",
    "    set_means = []\n",
    "    signal_traces = []\n",
    "    l_n = []\n",
    "\n",
    "    for trace_set in labels.values():\n",
    "        set_means.append(np.mean(trace_set, axis=0))  # take the mean along the column #good\n",
    "        for trace in trace_set:\n",
    "            l_n.append(trace - set_means[-1])\n",
    "        signal_traces.append(set_means[-1])\n",
    "\n",
    "    l_n = np.var(l_n, axis=0)\n",
    "    l_d = np.var(signal_traces, axis=0)\n",
    "\n",
    "    snr = np.divide(l_d, l_n)\n",
    "\n",
    "    return snr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T01:52:12.603279300Z",
     "start_time": "2023-11-24T01:52:12.478555900Z"
    }
   },
   "id": "303cf73826670303"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Score and Rank\n",
    "The score and rank metric is a helpful metric to use both during an attack and in the analysis of a system. This metric relies primarily on two steps, first, the full-length cryptographic key is split into multiple segments, called partitions. Typically, these partitions are the size of a byte, but can be either larger or shorter depending on the particular encryption algorithm and user implementation. This means that for partitions that are the size of a byte, there are 256 key possibilities. Next, a scoring function needs to be specified. This function is arbitrary but needs to return a numerical scores such that the higher the score, the more likely a given input key, k, actually produced the traces. Using the scoring function, for each partition, each possible key is ranked from the highest score to the lowest score. The idea of ranking and scoring the key guesses is that as the number of traces increases, the rank will converge to the point that the actual key will remain in the 1st rank, or very close to it for all key partitions. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a63106a69955bd04"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def score_and_rank(traces, score_fcn, key_candidates, partitions):\n",
    "        dtype = [('key', int), ('score', 'float64')]\n",
    "        ranks = []\n",
    "        # for each key partition        \n",
    "        for i in range(partitions): \n",
    "            partition_scores = np.array([], dtype=dtype)\n",
    "            \n",
    "            # for each key guess in the partition score the value and add to list\n",
    "            for k in key_candidates:\n",
    "                score_k = score_fcn(traces, k)\n",
    "                key_score = np.array([(k, score_k)], dtype=dtype)\n",
    "                partition_scores = np.append(partition_scores, key_score)\n",
    "                \n",
    "            # rank each key where partition_ranks[0] is the key that scored the highest\n",
    "            partition_ranks = np.array([key_score[0] for key_score in np.sort(partition_scores, order='score')[::-1]])\n",
    "            \n",
    "            ranks.append(partition_ranks)\n",
    "        return ranks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T01:52:12.605175600Z",
     "start_time": "2023-11-24T01:52:12.498484300Z"
    }
   },
   "id": "45dde6602bcdcbc7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Success Rate\n",
    "In the analysis of a system, the Success Rate metric can be used alongside the Score and Rank metrics in order to help determine the security of a system. This metric is typically conducted by an evaluator not an attacker since the correct key for the cryptographic system must be known. The success rate of a given experiment, i, is defined as 1 if the correct key is ranked within the top o key guesses. The order, o, can be any value between 1 and K where K is the number of key guesses. When o is 1, the success rate is only 1 if the correct key was ranked first out of all possible key guesses. Similarly, if o is 2, the success rate will be 1 if the correct key is ranking within the top 2 ranks. \n",
    "\\begin{equation}\n",
    "    SR_{o}^{i}=\n",
    "    \\begin{cases}\n",
    "        \\text{1 if } k_{c} \\in [guess_{1}, guess_{2}, ..., guess_{o}]\\\\\n",
    "        \\text{0 otherwise}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "The overall success rate is defined as the sum of the success rates of all experiments divided by the number of experiments. Lower success rates indicate a high degree of system security and vise versa. \n",
    "\\begin{equation}\n",
    "    SR_{o}= \\frac{1}{p}\\sum_{i=1}^{p}SR_{o}^{i}\n",
    "\\end{equation}\n",
    "\n",
    "## Guessing Entropy\n",
    "Guessing Entropy is another similar metric that can analyze the security of a system. The Guessing Entropy is defined as the sum of the natural log of the rank of the correct key for all experiments. \n",
    "\\begin{equation}\n",
    "    GE^{i}=log_{2}(rank_{k_{c}})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    GE = \\frac{1}{p}\\sum_{i=1}^{p}GE^{i}\n",
    "\\end{equation}\n",
    "The guessing entropy metric conveys the average workload left in the attack. As the guessing entropy decreases the certainty of the key guess increases, to the point where at a GE of 0, the key guess is certain."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa1506f97238090e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d33245a26bb13225"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def success_rate_guessing_entropy(correct_key, ranks, order, num_experiments):\n",
    "    success_rate = 0\n",
    "    guessing_entropy = 0\n",
    "    \n",
    "    # for each experiment\n",
    "    for i in range(num_experiments):\n",
    "        \n",
    "        # check if correct key is within o ranks\n",
    "        for j in range(order):\n",
    "            if ranks[i][j] == correct_key:\n",
    "                success_rate += 1\n",
    "                break\n",
    "        \n",
    "        # guessing entropy is the log2 of the rank of the correct key\n",
    "        guessing_entropy += math.log2(ranks[i].index(correct_key) + 1)\n",
    "    \n",
    "    success_rate = success_rate / num_experiments\n",
    "    guessing_entropy = guessing_entropy / num_experiments\n",
    "    \n",
    "    return success_rate, guessing_entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T01:52:12.605175600Z",
     "start_time": "2023-11-24T01:52:12.521357600Z"
    }
   },
   "id": "3a8f43e33d17956"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pearson Correlation Coefficient\n",
    "Source: Hardware Hacking Handbook: https://github.com/HardwareHackingHandbook/notebooks/blob/main/labs/HHH_10_Splitting_the_Difference_Differential_Power_Analysis.ipynb\n",
    "Correlation can be used as a metric that compares two different trace sets. The first set of power traces are observed leakages relating to an intermediate value V. The second set are predicted power traces that were derived using some sort of leakage model g(.) relating to an intermediate algorithm output value V for the correct key guess.\n",
    "$$\n",
    "p_{k_{c}} = \\frac{\\sum_{i=1}^{n} (l_{i}- \\frac{1}{n} \\sum_{i=1}^{n} l_{i}) (g(f(x_{i},k_{c})) - \\frac{1}{n} \\sum_{i=1}^{n} g(f(x_{i},k_{c})))}{{\\sqrt{\\sum_{i=1}^{n}({l_i - \\frac{1}{n}\\sum_{i=1}^n}{l_i})^2} \\sqrt{\\sum_{i=1}^n{(g(f(x_{i},k_{c}))-\\frac{1}{n} \\sum_{i=1}^{n}{g(f(x_{i},k_{c}))})^2}}}}\n",
    "$$\n",
    "If the absolute value of the correlation between predicted traces modeled using the correct key, is greater than that of other key guesses, then the key will likely be able to be derived from a side channel attack. The pearson correlation can be used to create a correlation trace. The key can be derived by plotting the correlation trace for different key guesses. The correlation trace modeled using the correct key will have a spike in magnitude of the correlation. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68bf175bf51a034b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def pearson_correlation(predicted_leakage, observed_leakage, num_traces, num_samples):\n",
    "    \n",
    "    predicted_mean = np.mean(predicted_leakage, axis=0)\n",
    "    observed_mean = np.mean(observed_leakage, axis=0)\n",
    "    \n",
    "    numerator = np.zeros(num_samples)\n",
    "    denominator1 = np.zeros(num_samples)\n",
    "    denominator2 = np.zeros(num_samples)\n",
    "    \n",
    "    for d in range(num_traces):\n",
    "        l = observed_leakage[d] - observed_mean\n",
    "        g = predicted_leakage[d] - predicted_mean\n",
    "        \n",
    "        numerator = numerator + g * l \n",
    "        denominator1 = denominator1 + np.square(l)\n",
    "        denominator2 = denominator2 + np.square(g)\n",
    "        \n",
    "    correlation_trace = numerator / np.sqrt(denominator1 * denominator2)    \n",
    "    \n",
    "    return correlation_trace"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T21:51:21.787021900Z",
     "start_time": "2023-12-01T21:51:21.767020700Z"
    }
   },
   "id": "a9557b50f10b2111"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## T-Test with TVLA\n",
    "The goal of the t-test is to assess a deviceâ€™s security, drawing conclusions regarding its relative venerability of lack thereof. A useful TVLA configuration for side channel analysis includes testing a device with a fixed key by sending deterministic and non-deterministic plaintext values. The resulting traces are separated into two different subsets, $L_{rand}$ and $L_{fixed}$ corresponding to if they were recorded from fixed or random plaintext values. Using statistical hypothesis testing where H0 corresponds to the device being secure and H1 indicating that the device has security flaws, the following hypothesis test can let us draw security conclusions. \n",
    "$$\n",
    "\\hat{\\mu}_i = \\frac{1}{n_i} \\sum_{l \\in L_i} l \\ \\ where \\ \\ i \\in \\{rand, fixed\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_0: \\hat{\\mu}_{rand} = \\hat{\\mu}_{fixed} \\ \\ H_1: \\hat{\\mu}_{rand} \\neq \\hat{\\mu}_{fixed}\n",
    "$$\n",
    "\n",
    "The t-statistic value, t, can then be calculated via the following equation.\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2_{i} = \\frac{1}{n_i -1}\\sum_{l \\in L_i}(l - \\hat{\\mu}_i)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "t = \\frac{\\hat{\\mu}_{rand} - \\hat{\\mu}_{fixed}}\n",
    "{\\sqrt{\\frac{\\hat{\\sigma}^2_{rand}}{n_{rand}} - \\frac{\\hat{\\sigma}^2_{fixed}}{n_{fixed}}}}\n",
    "$$\n",
    "\n",
    "$H_0$ will be rejected if $|t|$ is greater than some threshold $th$. This threshold is commonly set $th = 4.5$, a value that minimizes the possibility of Type I errors. Therefore, we can conclude that the DUT is leaking information if the t-statistic passes the given threshold."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8f4e206539311d1"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def t_test_tvla(fixed, random, num_traces):\n",
    "    \n",
    "    # calculate t-statistic for each trace\n",
    "    t_stats = []    \n",
    "    for t in range(num_traces):\n",
    "        t_statistic, p_value = stats.ttest_ind(fixed[t], random[t], axis=0, equal_var=False)\n",
    "        t_stats.append(t_statistic)\n",
    "    \n",
    "    # high t-statistic and low p-values indicate that a given time sample leaks information\n",
    "    return t_stats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T04:18:53.926267500Z",
     "start_time": "2023-12-07T04:18:53.899041Z"
    }
   },
   "id": "bd9e04554a871567"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
